Starting comprehensive tests...

================================================================================
MEMORY STRESS TEST - 15 sequential requests
================================================================================

[Request 1/15]
  ‚úÖ Status: stop
  ‚è±Ô∏è  Time: 17.12s
  üìù Tokens: 250/285
  üìÑ Length: 829 chars
  ‚úÖ Complete: No
  ‚ö†Ô∏è  WARNING: Response may be truncated!
     Last 100 chars: ...ears. So the formula becomes A = 5000*(1 + 0.04/1)^(1*2). That simplifies to 5000*(1.04)^2. 

Calcul

[Request 2/15]
  ‚úÖ Status: stop
  ‚è±Ô∏è  Time: 16.81s
  üìù Tokens: 250/285
  üìÑ Length: 864 chars
  ‚úÖ Complete: Yes

[Request 3/15]
  ‚úÖ Status: stop
  ‚è±Ô∏è  Time: 16.81s
  üìù Tokens: 250/285
  üìÑ Length: 871 chars
  ‚úÖ Complete: No
  ‚ö†Ô∏è  WARNING: Response may be truncated!
     Last 100 chars: ...ut step by step.

First, calculate the rate per period: r/n = 0.04 / 1 = 0.04. Then add 1 to that: 1

[Request 4/15]
  ‚úÖ Status: stop
  ‚è±Ô∏è  Time: 16.82s
  üìù Tokens: 250/285
  üìÑ Length: 764 chars
  ‚úÖ Complete: No
  ‚ö†Ô∏è  WARNING: Response may be truncated!
     Last 100 chars: ...t simplifies to 5000*(1.04)^2. Calculating 1.04 squared... 1.04 * 1.04 is 1.0816. Then multiply by 5

[Request 5/15]
‚ùå Error: Exception: The read operation timed out

[Request 6/15]
‚ùå Error: HTTP 500: {"error":{"message":"CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 22.04 GiB of which 21.12 MiB is free. Including non-PyTorch memory, this process has 22.02 GiB memory in use. Of the allocated memory 21.83 GiB is allocated by PyTorch, and 11.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","type":"internal_error"}}

[Request 7/15]
‚ùå Error: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}

[Request 8/15]
‚ùå Error: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}

[Request 9/15]
‚ùå Error: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}

[Request 10/15]
‚ùå Error: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}

[Request 11/15]
‚ùå Error: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}

[Request 12/15]
‚ùå Error: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}

[Request 13/15]
‚ùå Error: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}

[Request 14/15]
‚ùå Error: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}

[Request 15/15]
‚ùå Error: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}

================================================================================
MEMORY STRESS TEST SUMMARY
================================================================================
Total requests: 15
Successful: 4
Failed: 11

‚ùå Errors:
  Request 5: Exception: The read operation timed out
  Request 6: HTTP 500: {"error":{"message":"CUDA out of memory. Tried to allocate 32.00 MiB. GPU 0 has a total capacity of 22.04 GiB of which 21.12 MiB is free. Including non-PyTorch memory, this process has 22.02 GiB memory in use. Of the allocated memory 21.83 GiB is allocated by PyTorch, and 11.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","type":"internal_error"}}
  Request 7: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}
  Request 8: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}
  Request 9: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}
  Request 10: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}
  Request 11: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}
  Request 12: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}
  Request 13: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}
  Request 14: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}
  Request 15: HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}

üìä Performance:
  Average time: 16.89s
  Min time: 16.81s
  Max time: 17.12s
  Average tokens: 250

================================================================================
FRENCH LANGUAGE TEST
================================================================================

[Test 1/4] Simple French question
Prompt: Expliquez bri√®vement ce qu'est une obligation (bond).
‚ùå HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}

[Test 2/4] French with explicit instruction
Prompt: Expliquez ce qu'est le CAC 40. R√©pondez UNIQUEMENT en fran√ßais, sans utiliser d'anglais.
‚ùå HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}

[Test 3/4] French calculation
Prompt: Si j'investis 10 000‚Ç¨ √† 5% pendant 3 ans, combien aurai-je? Montrez le calcul. R√©pondez en fran√ßais.
‚ùå HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}

[Test 4/4] French finance terms
Prompt: Qu'est-ce qu'une SICAV et comment fonctionne-t-elle? Expliquez en fran√ßais.
‚ùå HTTP 500: {"error":{"message":"CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","type":"internal_error"}}

================================================================================
FRENCH LANGUAGE TEST SUMMARY
================================================================================
Total tests: 4
French answers: 0/4
Complete answers: 0/4

‚ùå Some answers are not in French!

================================================================================
FINAL SUMMARY
================================================================================
Memory management: ‚ùå FAIL
French language: ‚ùå FAIL
